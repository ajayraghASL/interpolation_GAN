{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajay/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ajay/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ajay/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ajay/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ajay/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ajay/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import *\n",
    "from ops import *\n",
    "from datasets import *\n",
    "\n",
    "\n",
    "import imageio\n",
    "\n",
    "import pdb\n",
    "\n",
    "from msssim import tf_ms_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import *\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Finn(object):\n",
    "    def __init__(self, sess, df_dim, batch_size, dropout_prob, l1_weight, ssim_weight, clipping_weight, discriminator_weight, writer_path, video_path):\n",
    "        self.df_dim = df_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.l1_weight = l1_weight\n",
    "        self.ssim_weight = ssim_weight\n",
    "        self.clipping_weight = clipping_weight\n",
    "        self.discriminator_weight = discriminator_weight\n",
    "\n",
    "        self.sess = sess\n",
    "        self.writer_path = writer_path\n",
    "        self.filename = 'fbp'\n",
    "        self.video_path = video_path\n",
    "\n",
    "\n",
    "        data = generateDataSet(self.video_path)\n",
    "        self.train_doublets = data[\"train_doublets\"]\n",
    "        self.train_triplets = data[\"train_triplets\"]\n",
    "        self.train_singlets = self.train_triplets[:,:,:,3:6]\n",
    "        self.val_doublets = data[\"val_doublets\"]\n",
    "        self.val_targets = data[\"val_targets\"]\n",
    "        self.mean_img = data[\"mean_img\"]\n",
    "\n",
    "        self.input_height = self.train_doublets.shape[1]\n",
    "        self.input_width = self.train_doublets.shape[2]\n",
    "        self.dataset_name = 'fbp'\n",
    "\n",
    "        self.gen_layer_depths = [32, 64, 64, 128]\n",
    "        self.gen_filter_sizes = [3, 3, 3, 3]\n",
    "\n",
    "        self.max_outputs = 100\n",
    "\n",
    "    def discriminator(self, triplet, phase, reuse = False):\n",
    "        with tf.variable_scope(\"discriminator\") as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            h0 = lrelu(conv2d(triplet, self.df_dim, hh=4, ww=4, stride_w=2, stride_h=2, padding='VALID', name=\"d_h0_conv\"))\n",
    "            h1 = lrelu(bn(conv2d(h0, self.df_dim*2, hh=4, ww=4, stride_w=2, stride_h=2, padding='VALID', name=\"d_h1_conv\"), phase, name=\"d_h1_bn\"))\n",
    "            h2 = lrelu(bn(conv2d(h1, self.df_dim*4, hh=4, ww=4, stride_w=2, stride_h=2, padding='VALID', name=\"d_h2_conv\"), phase, name=\"d_h2_bn\"))\n",
    "            h3 = lrelu(bn(conv2d(h2, self.df_dim*8, hh=4, ww=4, stride_w=2, stride_h=2, padding='VALID', name=\"d_h3_conv\"), phase, name=\"d_h3_bn\"))\n",
    "            h4 = conv2d(h3, 1, hh=4, ww=4, padding='SAME')\n",
    "            #h4 = linear(tf.reshape(h3, [self.batch_size, -1]), 1, 'd_h3_lin')\n",
    "\n",
    "            return tf.nn.sigmoid(h4), h4\n",
    "\n",
    "    def generator(self, doublet):\n",
    "        with tf.variable_scope(\"generator\"):\n",
    "            conv_outputs = []\n",
    "\n",
    "            current_input = doublet\n",
    "            current_inputdepth = doublet.shape[3]\n",
    "            for i, outputdepth in enumerate(self.gen_layer_depths):\n",
    "                result = conv_block(current_input, self.is_training, self.gen_filter_sizes[i], outputdepth, name=('g_conv_block'+str(i)) )\n",
    "                conv_outputs.append(result)\n",
    "                current_input = result\n",
    "                current_inputdepth = outputdepth\n",
    "\n",
    "            z = current_input\n",
    "\n",
    "            rev_layer_depths = list(reversed(self.gen_layer_depths))\n",
    "            rev_filter_sizes = list(reversed(self.gen_filter_sizes))\n",
    "            rev_conv_outputs = list(reversed(conv_outputs))\n",
    "#             for i in rev_conv_outputs:\n",
    "#                 print(i.get_shape())\n",
    "\n",
    "            # deconv portion\n",
    "            for i, outputdepth in enumerate(rev_layer_depths[1:]): # reverse process exactly until last step\n",
    "\n",
    "                result = bilinear_resize_deconv_block(current_input, self.is_training, rev_filter_sizes[i], outputdepth, name=('g_deconv_block'+str(i)) )\n",
    "                if i <= 4:\n",
    "                    result = tf.nn.dropout(result, self.dropout_prob)\n",
    "                print( \"result\"+str(i), result.get_shape() )\n",
    "                print(\"conc\"+str(i),rev_conv_outputs[i+1].get_shape())\n",
    "                stack = tf.concat([result, rev_conv_outputs[i+1]], 3)\n",
    "                # print( i, stack.get_shape() )\n",
    "                current_input = stack\n",
    "\n",
    "            outputdepth = 3 # final image is 3 channel\n",
    "            h = bilinear_resize_tanh_deconv_block(current_input, self.is_training, rev_filter_sizes[-1], outputdepth, name=('g_tanh_deconv') )\n",
    "            return conv2d(h, outputdepth, hh=1, ww=1, mean=0.11, stddev=0.04, name='final_conv')\n",
    "\n",
    "    def build_model(self):\n",
    "        singlet_dims = [self.input_height, self.input_width, 3]\n",
    "        image_dims = [self.input_height, self.input_width, 6]\n",
    "        triplet_dims = [self.input_height, self.input_width, 9]\n",
    "\n",
    "        # Set up placeholders\n",
    "        self.singlets = tf.placeholder(tf.float32, [self.batch_size] + singlet_dims, name = 'singlets')\n",
    "        self.doublets = tf.placeholder(tf.float32, [self.batch_size] + image_dims, name = 'doublets')\n",
    "        self.triplets = tf.placeholder(tf.float32, [self.batch_size] + triplet_dims, name = 'triplets')\n",
    "        self.is_training = tf.placeholder(tf.bool, (), name = 'is_training')\n",
    "\n",
    "        sing_mean_added = self.singlets + self.mean_img\n",
    "\n",
    "        # Sample generated frame from generator\n",
    "        self.G = self.generator(self.doublets)\n",
    "        g_mean_added = self.G + self.mean_img\n",
    "#         g_mean_added_clipped = tf.clip_by_value(g_mean_added, 0, 1)\n",
    "\n",
    "        # Assemble fake triplets using generated frame\n",
    "        self.before, self.after = tf.split(self.doublets, [3, 3], 3)\n",
    "        self.fake_triplets = tf.concat([self.before, self.G, self.after], 3)\n",
    "\n",
    "        # Evaluate discrimator on real triplets\n",
    "        self.D_real, self.D_real_logits = self.discriminator(self.triplets, self.is_training, reuse=False)\n",
    "        # Use same discriminator on fake triplets\n",
    "        self.D_fake, self.D_fake_logits = self.discriminator(self.fake_triplets, self.is_training, reuse=True)\n",
    "\n",
    "        # Calculate GAN losses\n",
    "        self.d_loss_real = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D_real_logits, labels=tf.ones_like(self.D_real)))\n",
    "        self.d_loss_fake = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D_fake_logits, labels=tf.zeros_like(self.D_fake)))\n",
    "        self.g_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D_fake_logits, labels=tf.ones_like(self.D_fake)))\n",
    "\n",
    "        # Calculate auxiliary losses\n",
    "        self.ms_ssim_loss = tf.reduce_mean(-tf.log(tf_ms_ssim(g_mean_added, sing_mean_added)))\n",
    "\n",
    "        eps = 1e-5\n",
    "        self.l1_loss = tf.reduce_mean(tf.sqrt(tf.square(self.G - self.singlets) + eps))\n",
    "\n",
    "#         self.clipping_loss = tf.reduce_mean(tf.square(g_mean_added - g_mean_added_clipped))\n",
    "\n",
    "        # Combine losses into single functions for the discriminator and the generator\n",
    "        self.d_loss_total = self.d_loss_fake + self.d_loss_real\n",
    "#         self.g_loss_total = self.discriminator_weight*self.g_loss + \\\n",
    "#                                 self.l1_weight*self.l1_loss + \\\n",
    "#                                 self.ssim_weight*self.ms_ssim_loss + \\\n",
    "#                                 self.clipping_weight*self.clipping_loss\n",
    "        self.g_loss_total = self.discriminator_weight*self.g_loss + \\\n",
    "                                self.l1_weight*self.l1_loss + \\\n",
    "                                self.ssim_weight*self.ms_ssim_loss\n",
    "\n",
    "\n",
    "        # Record relevant variables to TensorBoard\n",
    "        #  - discriminator logistic output\n",
    "        self.d_real_sum = tf.summary.histogram(\"d_real\", self.D_real)\n",
    "        self.d_fake_sum = tf.summary.histogram(\"d_fake\", self.D_fake)\n",
    "        #  - discriminator losses on real and fake images\n",
    "        self.d_loss_real_sum = tf.summary.scalar(\"real_loss\", self.d_loss_real)\n",
    "        self.d_loss_fake_sum = tf.summary.scalar(\"fake_loss\", self.d_loss_fake)\n",
    "        self.d_loss_total_sum = tf.summary.scalar(\"D_loss_total\", self.d_loss_total)\n",
    "        #  - generator losses\n",
    "        self.g_loss_sum = tf.summary.scalar(\"G_loss\", self.g_loss)\n",
    "        self.l1_loss_sum = tf.summary.scalar(\"l1_loss\", self.l1_loss)\n",
    "        self.ms_ssim_loss_sum = tf.summary.scalar(\"ms_ssim_loss\", self.ms_ssim_loss)\n",
    "#         self.clipping_loss_sum = tf.summary.scalar(\"clipping_loss\", self.clipping_loss)\n",
    "        self.g_loss_total_sum = tf.summary.scalar(\"G_total_loss\", self.g_loss_total)\n",
    "        # - sample images\n",
    "        self.num_images = self.batch_size\n",
    "\n",
    "        # clipped_G_img = tf.nn.clip_by_value(self.G + self.mean_img, 0,1)\n",
    "        clipped_G_img = self.G + self.mean_img\n",
    "        self.G_image = tf.summary.image(\"G\", clipped_G_img,\n",
    "            max_outputs=self.max_outputs)\n",
    "        self.before_image = tf.summary.image(\"Z1\", self.before + self.mean_img, max_outputs=self.max_outputs)\n",
    "        self.after_image = tf.summary.image(\"Z2\", self.after + self.mean_img, max_outputs=self.max_outputs)\n",
    "\n",
    "        # Collect trainable variables for the generator and discriminator\n",
    "        t_vars = tf.trainable_variables()\n",
    "        self.d_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "        self.g_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def train(self, config):\n",
    "\n",
    "\n",
    "        global_step = tf.placeholder(tf.float32, shape=[])\n",
    "        g_learning_rate = tf.train.exponential_decay(config.g_learning_rate, global_step,\n",
    "                                                   1, 0.96, staircase=True)\n",
    "        d_learning_rate = tf.train.exponential_decay(config.d_learning_rate, global_step,\n",
    "                                                   1, 0.96, staircase=True)\n",
    "        g_optim_l1 = tf.train.AdamOptimizer(g_learning_rate, beta1=config.beta1\n",
    "                                         ).minimize(self.l1_loss, var_list=self.g_vars)\n",
    "\n",
    "        g_optim = tf.train.AdamOptimizer(g_learning_rate, beta1=config.beta1\n",
    "                                         ).minimize(self.g_loss_total, var_list=self.g_vars)\n",
    "        d_optim = tf.train.AdamOptimizer(d_learning_rate, beta1=config.beta1\n",
    "                                                    ).minimize(self.d_loss_total, var_list=self.d_vars)\n",
    "\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        self.g_sum = tf.summary.merge([self.g_loss_sum, self.l1_loss_sum, self.ms_ssim_loss_sum,\n",
    "                                        self.g_loss_total_sum, self.d_loss_fake_sum, self.d_fake_sum])\n",
    "        self.g_sum_l1 = tf.summary.merge([self.l1_loss_sum])\n",
    "        self.d_sum = tf.summary.merge([self.d_loss_real_sum, self.d_real_sum, self.d_loss_total_sum])\n",
    "        self.img_sum = tf.summary.merge([self.G_image, self.before_image, self.after_image])\n",
    "        self.writer = tf.summary.FileWriter(self.writer_path + \"/\" + self.filename, self.sess.graph)\n",
    "\n",
    "\n",
    "        train_doublets = self.train_doublets\n",
    "        train_triplets = self.train_triplets\n",
    "        val_doublets = self.val_doublets\n",
    "        val_targets = self.val_targets\n",
    "        train_singlets = self.train_singlets\n",
    "\n",
    "        train_triplets_idx = np.arange(train_triplets.shape[0])\n",
    "        np.random.shuffle(train_triplets_idx)\n",
    "        # train_doublets_idx = np.arange(train_doublets.shape[0])\n",
    "        # np.random.shuffle(train_doublets_idx)\n",
    "        train_doublets_idx = train_triplets_idx\n",
    "\n",
    "\n",
    "        counter = 1\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(config.epoch):\n",
    "            print(epoch)\n",
    "            batch_idx = len(train_doublets) // self.batch_size\n",
    "\n",
    "\n",
    "            for idx in range(0, batch_idx):\n",
    "                batch_images_idx = train_triplets_idx[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_images = train_triplets[batch_images_idx]\n",
    "\n",
    "                batch_zs_idx = train_doublets_idx[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_zs = train_doublets[batch_zs_idx]\n",
    "\n",
    "                batch_targets = train_singlets[batch_images_idx]\n",
    "\n",
    "\n",
    "                if(config.train_gan):\n",
    "                    # Update D network\n",
    "                    _, summary_str = self.sess.run([d_optim, self.d_sum],\n",
    "                                                   feed_dict={\n",
    "                                                       self.triplets: batch_images,\n",
    "                                                       self.doublets: batch_zs,\n",
    "                                                       self.is_training: True,\n",
    "                                                       global_step: epoch\n",
    "                                                   })\n",
    "                    self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                    # Update G Network\n",
    "                    _, summary_str = self.sess.run([g_optim, self.g_sum],\n",
    "                                                   feed_dict={\n",
    "                                                       self.doublets: batch_zs,\n",
    "                                                       self.is_training: True,\n",
    "                                                       self.singlets: batch_targets,\n",
    "                                                       global_step: epoch\n",
    "                                                   })\n",
    "                    _, summary_str = self.sess.run([g_optim, self.g_sum],\n",
    "                                                  feed_dict={\n",
    "                                                      self.doublets: batch_zs,\n",
    "                                                      self.is_training: True,\n",
    "                                                      self.singlets: batch_targets,\n",
    "                                                      global_step: epoch\n",
    "                                                  })\n",
    "                    self.writer.add_summary(summary_str, counter)\n",
    "                else:\n",
    "                    # Update G Network\n",
    "                    _, summary_str = self.sess.run([g_optim_l1, self.g_sum_l1],\n",
    "                                                   feed_dict={\n",
    "                                                       self.doublets: batch_zs,\n",
    "                                                       self.is_training: True,\n",
    "                                                       self.singlets: batch_targets,\n",
    "                                                       global_step: epoch\n",
    "                                                   })\n",
    "                    self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "                errD_fake = self.d_loss_fake.eval({ self.doublets: batch_zs, self.is_training: True})\n",
    "                errD_real = self.d_loss_real.eval({ self.triplets: batch_images, self.is_training: True})\n",
    "                errG = self.g_loss.eval({self.doublets: batch_zs, self.is_training: True})\n",
    "                errG_l1 = self.l1_loss.eval({self.doublets: batch_zs, self.singlets: batch_targets, self.is_training: True})\n",
    "                errG_ssim = self.ms_ssim_loss.eval({self.doublets: batch_zs, self.singlets: batch_targets, self.is_training: True})\n",
    "                \n",
    "                \n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss_total %.8f, g_loss %.8f, l1_loss %.8f, ms_ssim_loss %.8f\" \\\n",
    "                      % (epoch, idx, batch_idx, time.time() - start_time, errD_fake+errD_real, errG, errG_l1, errG_ssim))\n",
    "\n",
    "                if idx % 5 == 0:\n",
    "                    summary_str = self.sess.run(self.img_sum,\n",
    "                                                   feed_dict = {\n",
    "                                                       self.doublets: train_doublets[train_doublets_idx[0:config.batch_size]],\n",
    "                                                       self.is_training: True,\n",
    "                                                   })\n",
    "                    self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "\n",
    "            if np.mod(epoch, 5) == 0:\n",
    "                self.save(config.checkpoint_dir, counter)\n",
    "\n",
    "                # Save images to file\n",
    "                # clipped_G_img = clip_keeping_color(self.G + self.mean_img)\n",
    "                clipped_G_img = self.G + self.mean_img\n",
    "\n",
    "                G_img = [self.sess.run(clipped_G_img,\n",
    "                                           feed_dict = {\n",
    "                                               self.doublets: train_doublets[k*self.batch_size:(k+1)*self.batch_size] ,\n",
    "                                               self.is_training: True,\n",
    "                                           }) for k in range(train_doublets.shape[0] // self.batch_size)]\n",
    "\n",
    "                G_img = np.stack(G_img, axis=0)\n",
    "                print('Saving images...')\n",
    "                imageio.imwrite(config.image_dir+\"mean_img.png\",self.mean_img)\n",
    "                [ imageio.imwrite(os.path.join(config.image_dir,\"G_epoch%dimg%d.png\" %\n",
    "                 (epoch, i)), np.squeeze(G_img[i])) for i in range(G_img.shape[0]) ]\n",
    "\n",
    "                if(epoch == 0):\n",
    "                    # Save the targets\n",
    "\n",
    "                    # Z_imgs = train_doublets[train_doublets_idx[0:config.batch_size]]\n",
    "                    Z_imgs = train_doublets\n",
    "                    [ imageio.imwrite(os.path.join(config.image_dir,\"Z13_epoch%dimg%d.png\" %\n",
    "                     (epoch, i)), (Z_imgs[i,:,:,:3] + Z_imgs[i,:,:,3:])/2 + self.mean_img) for i in range(Z_imgs.shape[0]) ]\n",
    "                    \n",
    "                    Z1_imgs = train_doublets\n",
    "                    [ imageio.imwrite(os.path.join(config.image_dir,\"Z1_epoch%dimg%d.png\" %\n",
    "                     (epoch, i)), (Z1_imgs[i,:,:,:3]  + self.mean_img)) for i in range(Z1_imgs.shape[0]) ]\n",
    "                    \n",
    "                    Z3_imgs = train_doublets\n",
    "                    [ imageio.imwrite(os.path.join(config.image_dir,\"Z3_epoch%dimg%d.png\" %\n",
    "                     (epoch, i)), (Z3_imgs[i,:,:,3:]  + self.mean_img)) for i in range(Z3_imgs.shape[0]) ]\n",
    "                    \n",
    "                    # S_imgs = train_singlets[train_doublets_idx[0:config.batch_size]]\n",
    "                    S_imgs = train_singlets\n",
    "                    [ imageio.imwrite(os.path.join(config.image_dir,\"Z2_epoch%dimg%d.png\" %\n",
    "                     (epoch, i)), S_imgs[i] + self.mean_img) for i in range(S_imgs.shape[0]) ]\n",
    "\n",
    "\n",
    "                print('Images saved!')\n",
    "\n",
    "    def test(self, config):\n",
    "        self.load(config.checkpoint_dir)\n",
    "\n",
    "        clipped_G_img = tf.clip_by_value(self.G + self.mean_img, 0,1)\n",
    "\n",
    "        G_img = [self.sess.run(clipped_G_img,\n",
    "                   feed_dict = {\n",
    "                       self.doublets: self.val_doublets[k*self.batch_size:(k+1)*self.batch_size] ,\n",
    "                       self.is_training: True,\n",
    "                   }) for k in range(self.val_doublets.shape[0] // self.batch_size)]\n",
    "\n",
    "        G_img = np.stack(G_img, axis=0)\n",
    "\n",
    "        print('Saving images...')\n",
    "        [ imageio.imwrite(os.path.join(config.test_image_dir,\"G_valimageno%d.png\" %\n",
    "                 (i)), np.squeeze(G_img[i]+self.mean_img)) for i in range(G_img.shape[0]) ]\n",
    "\n",
    "\n",
    "        Z_imgs = self.val_doublets\n",
    "        [ imageio.imwrite(os.path.join(config.test_image_dir,\"Z13_valimgno%d.png\" %\n",
    "                     (i)), (Z_imgs[i,:,:,:3] + Z_imgs[i,:,:,3:])/2 + self.mean_img) for i in range(Z_imgs.shape[0]) ]\n",
    "\n",
    "        Z_imgs = self.val_targets\n",
    "        [ imageio.imwrite(os.path.join(config.test_image_dir,\"Z2_valimagno%d.png\" %\n",
    "                     (i)), Z_imgs[i] + self.mean_img) for i in range(Z_imgs.shape[0]) ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def model_dir(self):\n",
    "        return \"{}_{}_{}_{}\".format(\n",
    "            self.dataset_name, self.batch_size,\n",
    "            self.input_height, self.input_width)\n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        model_name = \"DCGAN.model\"\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,\n",
    "                        os.path.join(checkpoint_dir, model_name),\n",
    "                        global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\", ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read {}\".format(ckpt_name))\n",
    "            return True, counter\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "\n",
    "    def __init__(self, epoch, g_learning_rate, d_learning_rate, beta1, batch_size):\n",
    "        self.epoch = epoch\n",
    "        self.g_learning_rate = g_learning_rate\n",
    "        self.d_learning_rate = d_learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.batch_size = batch_size\n",
    "        self.checkpoint_dir = '/home/ajay/work/Sparse CT/interpolation_GAN/Checkpoint/'\n",
    "        self.train_gan = True\n",
    "        self.image_dir = \"/home/ajay/work/Sparse CT/interpolation_GAN/output/train/\"\n",
    "        self.test_image_dir = \"/home/ajay/work/Sparse CT/interpolation_GAN/output/test/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 128, 128, 3)\n",
      "(18, 128, 128, 6)\n",
      "(18, 128, 128, 9)\n",
      "input_ (1, 128, 128, 6)\n",
      "input_ (1, 128, 128, 32)\n",
      "input_ (1, 64, 64, 32)\n",
      "input_ (1, 64, 64, 64)\n",
      "input_ (1, 32, 32, 64)\n",
      "input_ (1, 32, 32, 64)\n",
      "input_ (1, 16, 16, 64)\n",
      "input_ (1, 16, 16, 128)\n",
      "input_ (1, 16, 16, 128)\n",
      "input_ (1, 16, 16, 64)\n",
      "result0 (1, 16, 16, 64)\n",
      "conc0 (1, 16, 16, 64)\n",
      "input_ (1, 32, 32, 128)\n",
      "input_ (1, 32, 32, 64)\n",
      "result1 (1, 32, 32, 64)\n",
      "conc1 (1, 32, 32, 64)\n",
      "input_ (1, 64, 64, 128)\n",
      "input_ (1, 64, 64, 32)\n",
      "result2 (1, 64, 64, 32)\n",
      "conc2 (1, 64, 64, 32)\n",
      "input_ (1, 128, 128, 64)\n",
      "input_ (1, 128, 128, 3)\n",
      "input_ (1, 128, 128, 3)\n",
      "input_ (1, 128, 128, 9)\n",
      "input_ (1, 64, 64, 64)\n",
      "input_ (1, 32, 32, 128)\n",
      "input_ (1, 16, 16, 256)\n",
      "input_ (1, 8, 8, 512)\n",
      "input_ (1, 128, 128, 9)\n",
      "input_ (1, 64, 64, 64)\n",
      "input_ (1, 32, 32, 128)\n",
      "input_ (1, 16, 16, 256)\n",
      "input_ (1, 8, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    cfg = Config(epoch=100, g_learning_rate=.005, d_learning_rate=0.00005, beta1=0.5, batch_size=1)\n",
    "    tf.enable_eager_execution()\n",
    "\n",
    "    run_config = tf.ConfigProto()\n",
    "    run_config.gpu_options.allow_growth = True\n",
    "\n",
    "    with tf.Session(config=run_config) as sess:\n",
    "\n",
    "        df_dim = 64.\n",
    "        batch_size = cfg.batch_size\n",
    "        dropout_prob = 0.5 # probability of keeping\n",
    "        l1_weight = 16.\n",
    "        ssim_weight = 1.\n",
    "        clipping_weight = 10.\n",
    "        discriminator_weight = 1.\n",
    "        writer_path = './l1w_16_ssim_84_cw_10_dw_1'\n",
    "        file_path = \"/home/ajay/work/Sparse CT/cancerimagingarchivedata/Walnut1/data/0_255_[128]_tubev1.npy\"\n",
    "#         intermediate_path = \"/home/ajay/work/Sparse CT/cancerimagingarchivedata/intermediates/\"\n",
    "        finn = Finn(sess, df_dim, batch_size, dropout_prob, l1_weight, ssim_weight, clipping_weight, discriminator_weight, writer_path, file_path)\n",
    "        finn.build_model()\n",
    "        finn.train(cfg)\n",
    "        finn.test(cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
